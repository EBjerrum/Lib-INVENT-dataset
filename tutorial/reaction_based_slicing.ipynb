{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How to run this notebook (command-line)?**\n",
    "1. Install the `lib_invent_data` environment:\n",
    "`conda env -f environment.yml`\n",
    "2. Activate the environment:\n",
    "`conda activate lib_invent_data`\n",
    "3. Execute `jupyter`:\n",
    "`jupyter notebook`\n",
    "4. Copy the link to a browser\n",
    "\n",
    "\n",
    "# `Lib-INVENT Datasets`: Reaction Based Slicing Demo\n",
    "The purpose of this notebook is to illustrate how to generate a configuration for slicing compounds in a dataset based on reactions.\n",
    "\n",
    "Inputs:\n",
    "- A `dataset` with compounds SMILES. For the training of Lib-INVENT, the filtered ChEMBL 27 smiles were used. This dataset can be found in the Lib-INVENT project repository.\n",
    "- `reaction.smirks` file which contains reactions that will be used to slice the compounds.\n",
    "\n",
    "The `output SMILES file` will contain three columns including `scaffolds`, `decorations` and the `original compounds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "# --------- change these path variables as required\n",
    "lib_invent_dataset_project_dir = \"<path/to/your/project/>\"\n",
    "input_dataset_path = \"</path/to/input_smiles_file>\" \n",
    "                                                                                                   # unzip first\n",
    "reactions_file_path= os.path.join(lib_invent_dataset_project_dir, \"tutorial/data/reaction.smirks\")\n",
    "output_dir = \"</path/to/output_directory/>\"\n",
    "\n",
    "# --------- do not change\n",
    "# get the notebook's root path\n",
    "try: ipynb_path\n",
    "except NameError: ipynb_path = os.getcwd()\n",
    "\n",
    "# if required, generate a folder to store the results\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the configuration\n",
    "`Lib-INVENT datasets` has an entry point that loads a specified `JSON` file on startup. `JSON` is a low-level data format that allows to specify a fairly large number of parameters in a cascading fashion very quickly. The parameters are structured into *blocks* which can in turn contain blocks or simple values, such as *True* or *False*, strings and numbers. In this tutorial, we will go through the different blocks step-by-step, explaining their purpose and potential values for given parameters. Note, that while we will write out the configuration as a `JSON` file in the end, in `python` we handle the same information as a simple `dict`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `condition configuration` will be assembled first. This configuration will be used as an input in the reaction based slicing configuration, and the use for this configuration is to contain conditions used to filter scaffolds and decorations obtained from slicing molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_configuration={\n",
    "    \"scaffold\": [{\n",
    "        \"name\":\"ring_count\",\n",
    "        \"min\": 1\n",
    "    }],\n",
    "    \"decoration\": [\n",
    "    ]\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the configuration file to the disc\n",
    "condition_configuration_JSON_path = os.path.join(output_dir, \"filter_conditions.json\")\n",
    "with open(condition_configuration_JSON_path, 'w') as f:\n",
    "    json.dump(condition_configuration, f, indent=4, sort_keys= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `reaction based configuration` will be assembled by executing the 3 code block provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dictionary\n",
    "configuration = {\n",
    "    \"run_type\": \"reaction_based_slicing\"                                          \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration[\"parameters\"] = {\n",
    "    \"input_file\": input_dataset,\n",
    "    \"output_path\": os.path.join(output_dir, \"sliced\"),\n",
    "    \"output_smiles_file\": os.path.join(output_dir, \"reaction_smiles\"),\n",
    "    \"conditions_file\": condition_configuration_JSON_path,\n",
    "    \"reactions_file\": reactions_file_path,\n",
    "    \"max_cuts\": 4,                           # the maximum number of cuts to perform on each molecle\n",
    "    \"number_of_partitions\": 1000,\n",
    "    \"validate_randomization\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the configuration file to the disc\n",
    "configuration_JSON_path = os.path.join(output_dir, \"reaction_slicing_config.json\")\n",
    "with open(configuration_JSON_path, 'w') as f:\n",
    "    json.dump(configuration, f, indent=4, sort_keys= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run\n",
    "Execute in jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_err_stream --no-stderr \n",
    "\n",
    "# execute\n",
    "%cd <lib_invent_dataset_project_dir>\n",
    "!spark-submit --driver-memory=80g --conf spark.driver.maxResultSize=32g input.py <configuration_JSON_path>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the output to a file, just to have it for documentation\n",
    "with open(os.path.join(output_dir, \"run.err\"), 'w') as file:\n",
    "    file.write(captured_err_stream.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute in command line\n",
    "```\n",
    "# activate envionment\n",
    "conda activate lib_invent_data\n",
    "\n",
    "# go to the root folder of input.py \n",
    "cd </path/to/Lib-INVENT-datasets/directory>\n",
    "\n",
    "# execute in command line\n",
    "spark-submit --driver-memory=32g --conf spark.driver.maxResultSize=16g input.py </path/to/configuratoin.json>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
